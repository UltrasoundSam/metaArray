# -*- coding: utf-8 -*-
"""
Created on Mon Jan 29 2024 10:40

@author: samhill

This file contain a number of drivers to read the PZFlex output files.
These are only file patterns lib intended to be use by other programs
to actually the files.
"""
import numpy.typing as npt

from typing import Union
from os import linesep
from struct import calcsize
from numpy import frombuffer
from copy import copy

from .misc import filePath
from .misc import gettypecode
from .drv_fortran import binrecord
from .core import metaArray
from .metaFunc import metaResample


class FlexFiles:
    """
    This class of PZFlex output files, they include those generated by
    POUT and DATA OUT1.
    """

    def __init__(self, path: str = None,
                 debug: bool = False) -> None:
        self.parse_headers(path, debug=debug)

    def parse_headers(self, path: str = None,
                      debug: bool = False) -> None:
        """
        Parse the first four fortran records
        """
        # Attribute definitions
        self.debug = debug

        self.flg_resample = False
        # Sampling rate, only meaningful if flg_resample == True
        self.rate = False
        # Immune to resampling, internal use only
        self.flg_resample_immune = False

        self.records = None     # An instance of Fortran binary record file.
        self.endian = None

        # Header record structures
        self.hdr1 = None
        self.hdr2 = None
        self.hdr3 = None
        self.hdr4 = None
        # This is the internal storage of parsed record info
        self.hdr_nfo = None

        self.hdr_int_byte = None    # Header int length
        self.hdr_idata = None       # Unpack string for int type header

        self.fname = None       # Basic file ID name (w/o extension)
        self.fpath = None       # File path object
        self.date = None        # Date string for when the file was written
        self.title = None       # Model title
        self.tag = None         # Model tag
        self.code = None        # Simulation code used
        self.user = None        # User name
        self.iversion = None    # File type version number

        self.nrcd = None        # Number of non-header Fortran records

        self.int_byte = None    # Data array int length
        self.float_byte = None  # Data array float length
        self.idata = None       # Unpack string for int type data array
        self.fdata = None       # Unpack string for float type data array

        fpath = filePath(path)
        self.fname = fpath.name       # Basic file ID name (w/o extension)
        self.fpath = fpath            # File path object

        # Break down the file as binary fortran records first
        records = binrecord(path, debug)
        self.records = records
        self.nrcd = len(records) - 4

        # Endian of the file can be pick up from the binary record object
        self.endian = records.endian

        # Try to work out the byte length of the int, for header descriptions.
        # The first 4 bytes of the first header record is "hedr", the remaining
        # is an int.
        int_type = None
        length = len(records[0][4:])

        # Try the following int types
        try:
            int_type = gettypecode(length, 'int')
        except ValueError:
            # Bad luck, cant match the byte length.
            msg = "The first record do not appear to have the right length. \
            Expecting a 4 byte string 'hedr' and an int of the number 2. \
            Got '" + records[0][:4] + "' and '" + records[0][4:] + "' instead."
            raise ValueError(msg)

        self.hdr_int_byte = length
        self.hdr_idata = int_type

        if debug:
            print(linesep, "Begin parsing the records according to file spec.")

        # Begin parsing the redords
        parse = self.parse
        # This is the internal storage of parsed records
        hdr_nfo = []

        # Parse the first header
        hdr1 = []
        hdr1.append(['lhedr', 'c', 4, 'hedr'])
        hdr1.append(['itype', int_type, 1, 2])
        self.hdr1 = hdr1

        header1 = parse(hdr1, records[0])
        hdr_nfo.append(header1)

        if header1[0] != hdr1[0][3]:
            print('The first header record do not match description, ' +
                  'this binary record do not appear to be a Flex file.')

            raise ValueError(f'Header record 1, {hdr1[0][0]} should be: "' +
                             hdr1[0][3] + f'", got "{header1[0]}" instead.')

        if header1[1] != hdr1[1][3]:
            print('The first header record do not match description, ' +
                  'this binary record do not appear to be a Flex file.')

            raise ValueError(f'Header record 1, {hdr1[1][0]} should be: "' +
                             hdr1[1][3] + f'", got "{header1[1]}" instead.')

        # Parse the second header
        hdr2 = []
        hdr2.append(['ftype', 'c', 20, ''])
        hdr2.append(['fform', 'c', 20, 'bin                 '])
        hdr2.append(['date', 'c', 80, ''])
        hdr2.append(['code', 'c', 20, ''])
        hdr2.append(['user', 'c', 20, ''])
        hdr2.append(['extra1', 'c', 20, ''])
        hdr2.append(['extra2', 'c', 20, ''])
        self.hdr2 = hdr2

        header2 = parse(hdr2, records[1])
        hdr_nfo.append(header2)

        if header2[1] != hdr2[1][3]:
            print('The first header record do not match description, ' +
                  'this binary record do not seem to be a Flex pouthist file.')

            raise ValueError(f'Header record 1, {hdr2[1][0]} should be: '
                             f'{hdr2[1][3]}, got {header2[1]} instead.')

        self.date = header2[2].strip()
        self.code = header2[3].strip()
        self.user = header2[4].strip()

        if debug:
            print('Debug info for header record 2: ')
            print(f"This file is written at: {self.date}")

            self.code = header2[3].strip()
            self.user = header2[4].strip()
            print(f"This file is created by {self.user} using {self.code}")

            self.extra1 = header2[5].strip()
            print(f'20-Character variable (unused): {header2[5]}')

            self.extra2 = header2[6].strip()
            print(f'20-Character variable (unused): {header2[6]}')

            print("=== End of current record debug info ===", linesep)

        # Parse the third header
        hdr3 = []
        hdr3.append(['title', 'c', 200, ''])
        hdr3.append(['tag', 'c', 80, ''])
        self.hdr3 = hdr3

        header3 = parse(hdr3, records[2], strip=True)
        hdr_nfo.append(header3)

        self.title = header3[0]
        self.tag = header3[1]

        if debug:
            print('Debug info for header record 3: ')
            print(f"The title for this simulation is: {self.title}")
            print(f"The tag for this simulation is: {self.tag}")
            print("=== End of current record debug info ===", linesep)

        # Parse the fourth header
        hdr4 = []
        hdr4.append(['iversion', int_type, 1, ''])
        hdr4.append(['nparts', int_type, 1, ''])
        hdr4.append(['iparts', int_type, 1, ''])
        hdr4.append(['intbyt', int_type, 1, ''])
        hdr4.append(['irlbyt', int_type, 1, ''])
        hdr4.append(['nch1', int_type, 1, 20])
        hdr4.append(['nch2', int_type, 1, 80])
        hdr4.append(['nch3', int_type, 1, 200])
        hdr4.append(['iextra1', int_type, 1, ''])
        hdr4.append(['iextra2', int_type, 1, ''])
        self.hdr4 = hdr4

        header4 = parse(hdr4, records[3])
        hdr_nfo.append(header4)

        self.iversion = header4[0]
        self.int_byte = header4[3]
        self.float_byte = header4[4]

        if debug:
            print('Debug info for header record 4: ')
            self.file_version = header4[0]
            print(f"File version is: {self.file_version}")

            self.model_partitions = header4[1]
            print(f"This model has {header4[1]} partition(s).")

            self.file_partitions = header4[2]
            print(f"This file has {header4[2]} partiton(s).")

            print(f'Int variable is {header4[3]}  bytes long.')

            print(f'Float variable is {header4[4]} bytes long.')

            self.nch1 = header4[5]
            print(f'String 1 variable has {header4[5]} characters')

            self.nch2 = header4[6]
            print(f'String 2 variable has {header4[6]} characters')

            self.nch3 = header4[7]
            print(f'String 3 variable has {header4[7]}  characters')

            self.iextra1 = header4[8]
            print(f'Unused extra integer 1: {header4[8]}')

            self.iextra2 = header4[9]
            print(f'Unused extra integer 2: {header4[9]}')

            print("=== End of current record debug info ===", linesep)

        # Try to work out the unpack string for int data of intbyt in length,
        # for data array elements.
        idata = None
        int_byte = self.int_byte
        # Try the following int types
        # print int_byte
        idata = gettypecode(int_byte, 'int')
        self.idata = idata
        # for i in ['i', 'l', 'h', 'q']:
        #    if int_byte == calcsize(i):
        #         # Use the unpack type code that match the byte length
        #         idata = i
        #         self.idata = idata

        # Try to work out the unpack string for float data of intbyt in length,
        # for data array elements.
        fdata = None
        float_byte = self.float_byte

        # Try the following int types
        fdata = gettypecode(float_byte, 'float')
        self.fdata = fdata
        # for i in ['f', 'd']:
        #     if float_byte == calcsize(i):
        #         # Use the unpack type code that match the byte length
        #         fdata = i
        #         self.fdata = fdata

        if idata is None:
            # Bad luck, cant match the byte length.
            raise ValueError(f"The byte length ({int_byte}) of int variable \
            specified in header record 4 can not be matched to any \
            available int data types.")

        if fdata is None:
            # Bad luck, cant match the byte length.
            raise ValueError(f"The byte length ({float_byte}) of float \
            variable specified in header record 4 can not be matched to \
            any available float data types.")

        self.hdr_nfo = hdr_nfo

    def __call__(self) -> None:
        return self.nfo()

    def __getitem__(self, key):
        """
        Return the specified Fortran data record.
        """
        return self.get_data_item[key]

    def __len__(self) -> int:
        """
        Return the number of data records in the file
        """
        return int(self.nrcd)

    def get_data_item(self, key: int) -> bytes:
        """
        Return the specified Fortran data record.

        i.e.:
            records = binrecord(path, debug)
            self.records = records
            self[0] == records[4]
        """

        nrcd = self.nrcd

        # Do the ring buffer like trick
        if key < 0:
            key += nrcd

        # Sanity check for requested record number
        if key > nrcd:
            raise ValueError(f'Requested Fortrtan record number ({key}) does not exist, maximum availabe record number is: {nrcd - 1}')  # noqa: E501
        elif key < 0:
            raise ValueError(f'Requested Fortran record number ({key - nrcd}) does not exist.')  # noqa: E501

        # Translate the data number to record number
        key += 4

        return self.records[key]

    def nfo(self) -> None:
        '''
        Print Header info about Flex File
        '''
        print(56*'=')
        print(f'Header information of simulation file {self.fname}')
        print(56*'=')
        print(f'Simulation tag: {self.tag}')
        print(f'Simulation title: {self.title}')
        print(f'This flex file is generated at: {self.date}')
        print(f'By: {self.user}')
        print(f'This file has a file type version number of: {self.iversion}')
        print(f'There are a total of {self.ncrd} data records.')
        print(56*'=')

    def showIndex(self, N=None) -> None:
        """
        Print out the index statistics of the Nth record
        if N not specified, print them all out
        """
        return self.records.showIndex(N)

    def parse(self, structure: list[str, str, int, str], record: bytes,
              strip: bool = False) -> Union[npt.NDArray, str]:
        """
        Parse a binary byte stream against the structure

        Strip blank space for strings if strip == True

        Structure:
            [Name, var type, length, expected value/array shape]
            ['lhedr', 'c', 4, 'hedr'], .....

        Exceptions:
            If name is 'data', then use numpy to unpack directly
                If structure[3] is tuple type, data array will be
                reshaped according to structure[3]. The shape will be
                reversed and and the data array will be transposed by
                default. (i.e. C shape input -> read in Fortran order ->
                return data in C standard)

                Input for structure[3] is in the form of (x, y, z)

            If var type is 'c', no unpack will be done, forward the raw
                string
        """
        debug = self.debug
        endian = self.endian

        # The parsed entries to return to the caller
        entries = []

        current_index = 0
        for v_name, v_type, v_length, v_val in structure:
            # generate the unpack string
            unpack_str = f'{endian}{v_length}{v_type}'

            # Length of the current entry
            length = calcsize(f'{v_length}{v_type}')
            next_index = current_index + length

            # Different fields needs to be unpack differently
            if v_type == 'c':
                # These are strings, no need to unpack
                current_entry = record[current_index:next_index].decode()
                if strip:
                    current_entry = current_entry.strip()
            else:
                # These are numerical data
                current_entry = frombuffer(record[current_index:next_index],
                                           unpack_str)[0]
                if v_name == 'data':
                    # This is the main data bit, use numpy to unpack directly
                    if type(v_val) is tuple:
                        current_entry = current_entry.reshape(v_val[::-1]).T

            if debug >= 2:
                print(f"Parsed: {unpack_str} - [{current_index}:{next_index}] - {current_entry}")  # noqa: E501

            current_index = next_index
            entries.append(current_entry)

        return entries

    def len(self) -> int:
        """
        Return the number of data points for records in this file
        """
        return self.nrcd


class data_out1(FlexFiles):
    """
    The class define the data_out1 file object from PZFlex simulation

    Record patterns of the data_out1 file

    [name, type, length, value]
    """
    def __init__(self, path: str = None, debug: bool = False) -> None:

        self.debug = debug
        self.flg_ent_indexed = False    # Whether A records has been indexed

        self.A = None           # A record structure
        self.A1 = None          # A1 record structure

        self.A_idx = None       # An index of all the A records
        self.nentry = None      # Number of record entries, i.e. len(self.A_idx)

        # The list of data record descriptions (index)
        self.desc_lst = None

        # Parse the first 4 basic file header first
        self.parse_headers(path, debug)

        header2 = self.hdr_nfo[1]
        hdr2 = self.hdr2

        idata = self.idata
        fdata = self.fdata

        # Check if this agree with the spec
        if header2[0].strip() != 'dat1':
            print('The first header record do not match description, ' +
                  'this binary record do not seem to be a Flex data out1 file.')

            raise ValueError(f'Header record 1, {hdr2[0][0]} should be: ' +
                             f'"dat1", got "{header2[0]}" instead.')

        # The following are skeleton descriptions, have to fill in the
        # blanks before being used to parse the actual data records.
        # [name, type, length, value]

        # Record A, name
        # length,ntmstp,time,ndim,irange,jrange,krange,itype,ipart,iext1,iext2
        A = []
        A.append(['name', 'c', 20, ''])
        A.append(['length', idata, 1, ''])
        A.append(['ntmstp', idata, 1, ''])
        A.append(['time', fdata, 1, ''])
        A.append(['ndim', idata, 1, ''])
        A.append(['irange', idata, 1, ''])
        A.append(['jrange', idata, 1, ''])
        A.append(['krange', idata, 1, ''])
        A.append(['itype', idata, 1, ''])
        A.append(['ipart', idata, 1, ''])
        A.append(['iext1', idata, 1, ''])
        A.append(['iext2', idata, 1, ''])

        # A1 only exist if A.ipart == 1
        A1 = []
        A1.append(['ibegin', idata, 1, ''])
        A1.append(['iend', idata, 1, ''])
        A1.append(['jbegin', idata, 1, ''])
        A1.append(['jend', idata, 1, ''])
        A1.append(['kbegin', idata, 1, ''])
        A1.append(['kend', idata, 1, ''])

        # Just the raw data stream type 1, exist if A.ipart == 0
        # B(1): (((data(i,j,k), i=1, irange), j=1, jrange), k=1, krange)
        # B1 = []

        # Just the raw data stream type 2, exist if A.ipart == 1
        # B(2): (((data(i,j,k), i=ibegin, iend), j=jbegin, jend),
        #                                        k=kbegin, kend)
        # B2 = []

        self.A = A
        self.A1 = A1

        # All the headers and file structures are ready, index the file
        # and generate a summary of the file
        self._index_A_()

    def __call__(self) -> str:
        return self.__repr__()

    def __getitem__(self, key: int) -> npt.NDArray:
        """
        Return the record entry data of the given record number
        """

        # Check if global resample flg is in effect
        if self.flg_resample and not self.flg_resample_immune:
            return self.resampled(key, smp_rate=self.rate)

        max_entry_idx = self.nentry - 1

        # Do the ring buffer like trick
        if key < 0:
            key += max_entry_idx

        # Check the sanity of the requested data number
        if key > max_entry_idx:
            print('Requested DATA OUT1 record number (' + str(key) +
                  ') does not exist, maximum availabe record number is: ' +
                  str(max_entry_idx))
            raise ValueError
        elif key < 0:
            print(f'Requested DATA OUT1 record number ({key - max_entry_idx}) does not exist.')  # noqa: E501
            raise ValueError

        # Create entry (A record) index
        # A_idx[n][0] = name        # Name of the data array
        # A_idx[n][1] = ntmstp      # Time step when data was saved
        # A_idx[n][2] = time        # Problem time when data was saved
        # A_idx[n][3] = B           # B record structure (type, length, shape)
        # A_idx[n][4] = B_pos       # Position of the first Fortran B record
        # A_idx[n][5] = B_parts     # Number of Fortran record parts
        # A_idx[n][6] = [ibegin, jbegin, kbegin]
        # A_idx[n][7] = [iend, jend, kend]
        entry_info = self.A_idx[key]

        B = entry_info[3]
        B_pos = entry_info[4]
        B_parts = entry_info[5]

        record_payload = b''   # binary byte stream
        parts = 0
        current_pos = B_pos
        while parts < B_parts:
            record_payload += self.records[current_pos]
            parts += 1
            current_pos += 1

        # print(str(len(record_payload) / 8))
        # print(str(B))

        # Parse the record, and only the last field is needed
        data = self.parse([B], record_payload)[0]

        return data

    def __len__(self) -> int:
        """
        Return the number of data records in the file
        """
        return int(self.nentry)

    def _index_A_(self) -> None:
        """
        This function index the all of the A records.
        """

        # Pre-load own attribute and methods
        records = self.records
        parse = self.parse
        nrcd = self.nrcd
        debug = self.debug
        idata = self.idata
        fdata = self.fdata  # Unpack string for float type data array
        A = self.A
        A1 = self.A1

        # [data, idata/fdata, length, shape]
        B = ['data', None, None, None]  # Common features shared by B1 and B2

        if debug:
            print("Indexing the file for A records... ")

        # Empty/init the A record index
        A_idx = []

        # Search and index each A record
        # If A1 exists, index parse that as well.
        # Start with the 0th data record, i.e. 5th Fortran record
        i = 4
        entry_number = 0
        while i < (nrcd + 3):
            # This is discription dictionary for the current record
            desc = {}

            # Parse data record A, i.e. the descriptions and header
            A_record = parse(A, records[i], strip=True)

            # Write into the description
            for j in range(len(A_record)):
                desc[A[j][0]] = A_record[j]

            # name = desc['name']
            length = desc['length']
            # ntmstp = desc['ntmstp']
            # time = desc['time']
            ndim = desc['ndim']

            irange = desc['irange']
            jrange = desc['jrange']
            krange = desc['krange']

            ipart = desc['ipart']
            itype = desc['itype']

            # Value checks and define the array shape in the B record structure
            if ndim == 3:
                # 3D array
                B[3] = (krange, jrange, irange)
            elif ndim == 2:
                B[3] = (jrange, irange)
                if krange != 1:
                    msg = "The record header (A.ndim) suggests this is a \
                    two dimentional array, conflicts with A.krange, \
                    A.krange should be 1 \
                    Current Fortran record index is: " + str(i)
                    raise ValueError(msg)
            elif ndim == 1:
                if krange != 1 or jrange != 1:
                    msg = "The record header (A.ndim) suggests this is a \
                    one dimentional array, A.jrange and A.krange should be 1.\
                    Current Fortran record index is: " + str(i)
                    raise ValueError(msg)
            else:
                raise ValueError(f"The record header (A.ndim = {ndim}) is incorrect. Current Fortran record index is: {i}")  # noqa: E501

            # A record is now understood, read A1 record if necessary
            if ipart == 1:
                # A[ipart] is 1, only a portion of the record is contained
                # in Record B2
                # Has A1 and data in B2 format
                i += 1
                A1_record = parse(A1, records[i])

                for j in range(len(A1_record)):
                    desc[A1[j][0]] = A1_record[j]

                ibegin = desc['ibegin']
                jbegin = desc['jbegin']
                kbegin = desc['kbegin']

                iend = desc['iend']
                jend = desc['jend']
                kend = desc['kend']

                ilen = (iend - ibegin + 1)   # Beginning and ends inclusive
                jlen = (jend - jbegin + 1)
                klen = (kend - kbegin + 1)

                B[2] = ilen * jlen * klen   # Length of the array
                B[3] = (ilen, jlen, klen)   # Shape of the array

                i += 1
                B_parts = 1
                B_pos = i

            elif ipart == 0:
                # A[ipart] is 0, The entire array is contained in B1 format

                ibegin = 1
                jbegin = 1
                kbegin = 1

                iend = irange
                jend = jrange
                kend = krange

                B[2] = length                       # Length of the array
                B[3] = (irange, jrange, krange)   # Shape of the array

                # In B1 records, data is truncated in to 1,000,000 length pieces
                B_parts = 0             # Number of fortran record for B
                B_pos = i + 1
                # Difficult to do byte count, could be double precision
                B_len = B[2]
                while B_len > 0:
                    i += 1              # hop forward one record number
                    B_len -= records.item_len(i) / self.float_byte
                    B_parts += 1

                if B_len != 0:
                    # Somthing is wrong, the sum of all B records should
                    # have the same length as the array.
                    msg = ["Residual B record length incorrect, the "]
                    msg.append("total length of B records parts should be ")
                    msg.append("the same as the product of array ranges.")
                    msg.append(f"Current Fortran record number {i}")
                    msg.append(f"irange: {irange}")
                    msg.append(f"jrange: {jrange}")
                    msg.append(f"krange: {krange}")
                    msg.append(f'Residual B record length: {B_len}')
                    raise ValueError(f'{linesep}'.join(msg))
            else:
                msg = ["ipart value in A record can only be 1 or 0, "]
                msg.append(f"got {ipart} instead, current Fortran ")
                msg.append(f"record number is {i}")
                raise ValueError(f'{linesep}'.join(msg))

            # Define the B record data type
            if itype == 1:
                # is float
                B[1] = fdata
            elif itype == 2:
                # is Int
                B[1] = idata
            elif itype < 0 and itype > -20:
                # Character array
                B[1] = 'c'
            else:
                # Something is very wrong
                msg = "itype value in A record can only be from -20 to 1, got {itype} instead. Current Fortran record numer is {i}"  # noqa: E501
                raise ValueError(msg)

            # Create entry (A record) index
            # A_idx[n][0] = name        # Name of the data array
            # A_idx[n][1] = ntmstp      # Time step when data was saved
            # A_idx[n][2] = time        # Problem time when data was saved
            # A_idx[n][3] = B           # B record structure (type, length,
            #                                                 shape)
            # A_idx[n][4] = B_pos       # Position of the first Fortran B record
            # A_idx[n][5] = B_parts     # Number of Fortran record parts
            # A_idx[n][6] = [ibegin, jbegin, kbegin]
            # A_idx[n][7] = [iend, jend, kend]
            A_idx.append([desc['name'],
                          desc['ntmstp'],
                          desc['time'],
                          copy(B),
                          B_pos,
                          B_parts,
                          [ibegin, jbegin, kbegin],
                          [iend, jend, kend]])

            if debug:
                print("Index: " + str(entry_number) + "\t" +
                      "Name: " + desc['name'] + "\t" +
                      "ntmstp: " + str(desc['ntmstp']) + "\t" +
                      "time: " + str(desc['time']) + "\t" +
                      "B_pos: " + str(B_pos) + "\t" +
                      "B_parts: " + str(B_parts) + linesep +
                      "\t From: " + str([ibegin, jbegin, kbegin]) + "\t to " +
                      str([iend, jend, kend]))

                entry_number += 1

            # Finished parsing this entry, prepare to do the next one
            i += 1

        # Number of data entries
        self.nentry = len(A_idx)
        self.flg_ent_indexed = True
        self.A_idx = A_idx

    def transpose(self, name, drange) -> None:
        """
        Transpose the time sliced data entries, into time history array
        """
        return

    def showIndex(self) -> str:
        """
        Print an index of all record entries
        """
        if not self.flg_ent_indexed:
            self._index_A_()

        A_idx = self.A_idx

        desc = ''
        for i in range(self.nentry):
            sub = [f'{i}', f'{A_idx[i][0]}', f'{A_idx[i][1]}',
                   f'{A_idx[i][2]: 0.3e}', f'{A_idx[i][3][3]}',
                   f'{A_idx[i][6]} -> {A_idx[i][7]}{linesep}']
            desc += '\t'.join(sub)
        return desc

    def resampled(self, key: int, smp_rate: bool = False) -> metaArray:
        """
        Return the data that is resampled with standard sampling rates
        and aligned to time zero

        Unless the new sampling rate is specified, the next highest
        standard sampling rate will be used.
        """

        # Gain temporary immunity in order to obtain the raw data
        self.flg_resample_immune = True

        # Keep only the data array
        ary = metaResample(self[key], rate=smp_rate)

        # Loss the immunity after raw data is obtained.
        self.flg_resample_immune = False

        return ary

    def name(self, key: int) -> str:
        """
        Return the variable name for the given record number
        """
        return self.A_idx[key][0]

    def ntmstp(self, key: int) -> int:
        """
        Return the model time step number for the given record number
        """
        return self.A_idx[key][1]

    def time(self, key) -> float:
        """
        Return the model time stamp for the given record number
        """
        return self.A_idx[key][2]

    def range_begin(self, key: int) -> tuple[int, int, int]:
        """
        Return the starting i,j,k range for the given record number
        """
        return self.A_idx[key][6]

    def range_end(self, key: int) -> tuple[int, int, int]:
        """
        Return the ending i,j,k range for the given record number
        """
        return self.A_idx[key][7]

    def len(self) -> int:
        """
        Return the number of data points for records in this file
        """
        return self.ntim

    def global_resample(self, switch: bool,
                        smp_rate: float = False) -> None:
        """
        The switch method to activate the resampling behaviour.

        If switched on, __getitem__() will return the resampled data at
        the given sampling rate.

        If sampling rate is not specified, default is to use the next
        highest standard sampling rate.

        Example usage:
            self.global_resample(True, smp_rate=100e6)
        """
        if switch is True:
            self.flg_resample = True
            self.rate = smp_rate
        else:
            self.flg_resample = False

    def __repr__(self) -> str:
        """
        Text representation of the object
        """
        if not self.flg_ent_indexed:
            self._index_A_()

        desc = f'This is a PZFlex data_out1 file object at: {self.fpath.full}'
        desc += linesep
        desc += f'\tNumber of data records: {self.nentry}' + linesep
        desc += 'Index\tName\tntmstp\tTime\t\tShape\t\tRange' + linesep
        desc += self.showIndex()

        if self.flg_resample is True:
            desc += linesep
            desc += '=' * 72 + linesep

            if self.rate is False:
                desc += 'Items returned will be automatically resampled to the next ' + linesep  # noqa: E501
                desc += 'highest standard sampling rate according to metaArray.' + linesep  # noqa: E501
            else:
                desc += f'Items returned will be automatically resampled at: {self.rate} samples per unit time.' + linesep  # noqa: E501

            desc += '=' * 72 + linesep

        return desc


class pout_hist(FlexFiles):
    """
    The class define the pout_hist file object from PZFlex simulation


    Record patterns of the pout_hist file

    [name, type, length, value]
    """

    def __init__(self, path: str = None,
                 debug: bool = False) -> None:

        self.flg_debug = debug
        self.flg_indexed = False

        self.flg_resample = False

        # (re)Sampling rate, only meaningful if flg_resample == True.
        self.rate = False
        # Immune to resampling, internal use only
        # self.flg_resample_immune = False
        self.t0 = False             # Start time according to the time record
        self.t1 = False             # End time according to the time record
        # Number of (time) samples between self.t0 and self.t1
        self.tpts = False

        self.base = None            # Base record structure
        self.base_desc = None       # Base record description

        self.timeA = None           # timeA record structure
        self.timeB = None           # timeB record structure
        self.dataA = None           # dataA record structure
        self.dataB = None           # dataB record structure

        # Number of data records on the file including the time record
        self.nrecd = None
        # Number of time values for which time history data was saved
        self.ntim = None
        # Number of 20-character words for grid name = 1
        self.ngrd = None
        # Number of 20-character words for description = 1
        self.ndes = None
        # Number of 20-character words for curve tag = 1
        self.ntag = None
        # 1 = time shift for each record; 0 = no time shift
        self.nshift = None
        # Number of 20-character words for curve lable = 1
        self.nlabl = None
        # Number of indicies for each record
        self.nindx = None
        # Number of coordinates for each record
        self.ncord = None
        # Number of bytes per character word = 20
        self.nchr = None

        # The list of data record descriptions (index)
        self.desc_lst = None

        # Parse the first 4 basic file header first
        self.parse_headers(path, debug)

        header2 = self.hdr_nfo[1]
        hdr2 = self.hdr2

        int_byte = self.int_byte
        idata = self.idata
        fdata = self.fdata

        # Check if this agree with the spec
        if header2[0].strip() != 'hist':
            print('The first header record do not match description, ' +
                  'this binary record do not seem to be a Flex data out1 file.')

            raise ValueError(f'Header record 1, {hdr2[0][0]} should be: "dat1", got "{header2[0]}" instead')  # noqa: E501

        # Pre-load own attribute and methods
        records = self.records
        parse = self.parse

        # It turn out that the double precision pzflex code will write the base
        # record in double precision, but leave the header records at single
        # precision!!
        #
        # This is a quick fix to check whether the Base Record is written as
        # double precision, by assuming there are always exactly 12 int
        # variables in this record.
        int_byte = len(records[4]) / 12

        if int_byte != calcsize(idata):
            print('Warning! The length of Int variable (' + str(int_byte) +
                  ') appear to be different from which indicated by the Header_record_4.intbyt (' +  # noqa: E501
                  str(calcsize(idata)) + '). This may be a result of using the double ' +  # noqa: E501
                  'precision pzflex solver.' + linesep)

            if debug:
                msg = 'Warning! Try to work out the correct data type used.'
                print(msg + linesep)

            idata = gettypecode(int_byte, 'int')
            fdata = gettypecode(int_byte, 'float')

        # Parse the base record
        base = []
        base.append(['int12', idata, 1, 12])
        base.append(['nrecd', idata, 1, ''])
        base.append(['ntim', idata, 1, ''])
        base.append(['ngrd', idata, 1, ''])
        base.append(['ndes', idata, 1, ''])
        base.append(['ntag', idata, 1, ''])
        base.append(['nshift', idata, 1, ''])
        base.append(['nlabl', idata, 1, ''])
        base.append(['nindx', idata, 1, ''])
        base.append(['ncord', idata, 1, ''])
        base.append(['nchr', idata, 1, ''])
        base.append(['nextra', idata, 1, ''])
        self.base = base

        base_rcd = parse(base, records[4])
        base_desc = {}

        for j in range(len(base_rcd)):
            base_desc[base[j][0]] = base_rcd[j]

        # Check if this agree with the spec
        if base_desc['int12'] != base[0][3]:
            print('The first entry of the base record do not match description, this binary record maybe corrupted.')  # noqa: E501

            print(f"Base record 1, {base[0][0]} should be: {base[0][3]}, got {base_desc['int12']} instead.")  # noqa: E501

        self.nrecd = base_desc['nrecd']
        self.ntim = base_desc['ntim']
        self.ngrd = base_desc['ngrd']
        self.ndes = base_desc['ndes']
        self.ntag = base_desc['ntag']
        self.nlabl = base_desc['nlabl']
        self.nindx = base_desc['nindx']
        self.ncord = base_desc['ncord']
        nchr = base_desc['nchr']                    # Keep for local use
        self.nchr = nchr

        if base_desc['nshift'] == 0:
            self.nshift = False
        elif base_desc['nshift'] == 1:
            self.nshift = True
        else:
            raise ValueError('Unexpected time shift value in the base record of the file.' +   # noqa: E501
                             f"Expecting '1' or '0', but got {base_desc['nshift']} instead.")  # noqa: E501

        if debug:
            print('Debug info for the base record: ')
            print('There are a total of ' + str(base_rcd[1]) +
                  ' data records in this file, including the time record.')
            print(f'There are {base_rcd[2]} time values in the time record.')
            print(f'The grid name field is {base_rcd[3]} words long.')
            print(f'The description field is {base_rcd[4]} words long.')
            print(f'The curve tag field is {base_rcd[5]} words long.')
            if self.nshift:
                print('There is a time shift for each record.')
            else:
                print('There is no time shift for the records.')
            print(f'The curve label field is {base_rcd[7]} words long.')
            print(f'There are {base_rcd[8]} indicies for each record.')
            print(f'There are {base_rcd[9]} coordinates for each record.')
            print(f'Each character words has {base_rcd[10]} bytes.')
            print("=== End of current record debug info ===", linesep)

        # The following are skeleton descriptions, have to fill in the
        # blanks before being used to parse the actual data records.

        # Calculate the byte length for each field types
        llabl = self.nlabl * nchr
        ltag = self.ntag * nchr
        lgrd = self.ngrd * nchr
        ldes = self.ndes * nchr

        # Not yet implemented
        timeA = []
        timeA.append(['label', 'c', llabl, ''])
        timeA.append(['ldummy', 'c', nchr, ''])
        timeA.append(['ldesc', 'c', ldes, ''])

        # Not yet implemented
        timeB = []
        timeB.append(['zero', fdata, '', 0.0])
        timeB.append(['tstep', fdata, '', ''])
        timeB.append(['i0', idata, '', 0])
        timeB.append(['tbegin', fdata, '', ''])
        timeB.append(['tend', fdata, '', ''])
        timeB.append(['tshift', fdata, '', ''])
        timeB.append(['time', fdata, '', ''])

        dataA = []
        dataA.append(['label', 'c', llabl, ''])
        dataA.append(['ltag', 'c', ltag, ''])
        dataA.append(['lgrid', 'c', lgrd, ''])
        dataA.append(['ldesc', 'c', ldes, ''])

        dataB = []
        dataB.append(['xcrd', fdata, 1, ''])
        dataB.append(['ycrd', fdata, 1, ''])
        dataB.append(['zcrd', fdata, 1, ''])
        dataB.append(['i', idata, 1, ''])
        dataB.append(['j', idata, 1, ''])
        dataB.append(['k', idata, 1, ''])
        dataB.append(['datamin', fdata, 1, ''])
        dataB.append(['datamax', fdata, 1, ''])
        dataB.append(['tshift', fdata, 1, ''])
        dataB.append(['data', fdata, self.ntim, ''])

        self.timeA = timeA
        self.timeB = timeB
        self.dataA = dataA
        self.dataB = dataB

        # All the headers and file structures are ready, index the file
        # and generate a summary of the file
        self._index_()

        tary = self._getitem_raw_(0)

        # Start time according to the time record
        self.t0 = tary.data[0]
        # End time according to the time record
        self.t1 = tary.data[-1]
        # Number of (time) samples between self.t0 and self.t1
        self.tpts = len(tary)

    def __call__(self) -> str:
        return self.__repr__()

    def __repr__(self) -> str:
        """
        Text representation of the object
        """
        if not self.flg_indexed:
            self._index_()

        desc = [f'There are {len(self)} data record(s) in this PZFlex POUT HIST file object at: ']  # noqa: E501
        desc.append(f'\t{self.fpath.full}')
        desc.append(72*'=')
        desc.append(self.showIndex())
        desc.append(72*'=')
        desc.append(f'The time history records started at time: {self.t0}')
        desc.append(f'The time history records finished at time: {self.t1}')
        f0 = self.tpts / (self.t1 - self.t0)
        desc.append(f'There are {self.tpts} time samples, with the equivalent sampling rate of: {f0} Hz')  # noqa: E501

        if self.flg_resample is True:
            desc.append(72 * '=')

            if self.rate is False:
                desc.append('Items returned will be automatically resampled to the next ')  # noqa: E501
                desc.append('highest standard sampling rate according to metaArray.')  # noqa: E501
            else:
                desc.append(f'Items returned will be automatically resampled at: {self.rate} samples per unit time')  # noqa: E501

            desc.append(72 * '=')
        return f'{linesep}'.join(desc)

    def _getitem_raw_(self, key: int) -> metaArray:

        """
        Return the record data of the given record number
        """
        nrecd = self.nrecd

        # Do the ring buffer like trick
        if key < 0:
            key += nrecd

        # Check the sanity of the requested data number
        if key > nrecd:
            print('Requested pout hist record number (' + str(key) +
                  ') does not exist, maximum availabe record number is: ' +
                  str(nrecd))
            raise ValueError
        elif key < 0:
            print('Requested pout hist record number (' + str(key - nrecd) +
                  ') does not exist.')
            raise ValueError

        # Descriptions of this record
        desc = self.desc_lst[key]

        # Translate the data number to record number
        key = 6 + 2 * key

        # Parse the record, and only the last field is needed
        data = self.parse(self.dataB, self.records[key])[-1]
        data = metaArray(data)

        # Update the basic metaArray info
        data['name'] = self.tag
        data['label'] = desc['label']

        # Record 0 is always the time series
        # Double check to make sure
        time = self.desc_lst[0]
        while True:
            if time['label'] != 'time':
                break

            if time['ltag'] != 'time':
                break

            if time['lgrid'] != 'time':
                break

            t0 = time['datamin']
            t1 = time['datamax']

            break

        t0 += desc['tshift']
        t1 += desc['tshift']

        data.set_range(0, 'begin', t0)
        data.set_range(0, 'end', t1)
        data['range']['label'][0] = 'time'

        # Include the rest of the metainfo into metaArray
        for field, value in desc.iteritems():
            data["POUT_hist."+field] = value

        data[self.fname + '.desc'] = self.title
        data[self.fname + '.date'] = self.date

        return data

    def __getitem__(self, key: int) -> metaArray:
        """
        Return the record data of the given record number
        """

        # If there are no need to resample
        if self.flg_resample is False:
            return self._getitem_raw_(key)

        # Resampling necessary
        data = metaResample(self._getitem_raw_(key), rate=self.rate)

        return data

    def __len__(self) -> int:
        """
        Return the number of data records in the file
        """
        return int(self.nrecd)

    def _index_(self) -> None:
        """
        This function index the pout content in a abstract record list.
        """
        # This is the list of descriptions for the data records
        desc_lst = []

        # Pre-load own attribute and methods
        records = self.records
        parse = self.parse
        dataA = self.dataA
        dataB = self.dataB[:-1]  # No need to load the entire data array

        # Index each data record
        for i in range(self.nrecd):
            # This is discription dictionary for the current record
            desc = {}

            # Record index for the current data record
            # Starting from the 6th record, because there are 5 header
            # records.
            idataA = 5 + 2 * i
            idataB = idataA + 1

            # Parse data record A, i.e. the descriptions
            # and header of data record B
            A_record = parse(dataA, records[idataA], strip=True)
            B_record = parse(dataB, records[idataB], strip=True)

            # Populate the description dict
            # dataA[i][0] is the name of the data field
            for i in range(len(A_record)):
                desc[dataA[i][0]] = A_record[i]

            for i in range(len(B_record)):
                desc[dataB[i][0]] = B_record[i]

            desc_lst.append(desc)

        self.desc_lst = desc_lst
        self.flg_indexed = True

    def showIndex(self) -> str:

        desc_lst = self.desc_lst

        desc = ''
        desc += 'Simulation tag: ' + self.tag + linesep
        desc += 'Simulation title: ' + self.title + linesep
        desc += 'This flex pout hist file is generated at: ' + self.date
        desc += linesep

        desc += 'This file has ' + str(self.nrecd) + ' data records: ' + linesep

        for i in range(len(desc_lst)):
            desc += 'Record number ' + str(i) + ':' + linesep
            desc += '\t Label: ' + desc_lst[i]['label'] + linesep

            xyz = '(' + str(desc_lst[i]['xcrd']) + ', '
            xyz += str(desc_lst[i]['ycrd']) + ', '
            xyz += str(desc_lst[i]['zcrd']) + ')'
            desc += '\t x-y-z location: ' + xyz + linesep

            ijk = '(' + str(desc_lst[i]['i']) + ', '
            ijk += str(desc_lst[i]['j']) + ', '
            ijk += str(desc_lst[i]['k']) + ')'
            desc += '\t i-j-k location: ' + ijk + linesep
            desc += '\t number of data points: ' + str(self.ntim) + linesep

        return desc

    def name(self, key: int) -> str:
        """
        Return the variable name for the given record number
        """
        return self.desc_lst[key]['label']

    def len(self) -> int:
        """
        Return the number of data points for records in this file
        """
        return self.ntim

    def global_resample(self, switch: bool,
                        smp_rate: float = False) -> None:
        """
        The switch method to activate the resampling behaviour.

        If switched on, __getitem__() will return the resampled data at
        the given sampling rate.

        If sampling rate is not specified, default is to use the next
        highest standard sampling rate.

        Example usage:
            self.global_resample(True, smp_rate=100e6)
        """
        if switch is True:
            self.flg_resample = True
            self.rate = smp_rate
        else:
            self.flg_resample = False

        return
